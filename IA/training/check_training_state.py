#check_training_state.py
#!/usr/bin/env python3
"""
Script rapide pour vÃ©rifier l'Ã©tat d'entraÃ®nement (pour Colab)
Usage: python check_training_state.py
"""

import sys
import os
from pathlib import Path
import torch

# Chemin des checkpoints
CHECKPOINT_DIR = Path("./IA/saved_models/my_llm/checkpoints")

def check_training_state():
    """VÃ©rifie et affiche l'Ã©tat d'entraÃ®nement"""
    print("\n" + "="*70)
    print("ğŸ“Š Ã‰TAT D'ENTRAÃNEMENT - VÃ‰RIFICATION RAPIDE")
    print("="*70)
    
    # Chercher l'Ã©tat d'entraÃ®nement
    state_path = CHECKPOINT_DIR / "training_state.pt"
    
    if not state_path.exists():
        # Chercher un backup
        backups = sorted(
            CHECKPOINT_DIR.glob("state_backup_*.pt"),
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )
        if backups:
            state_path = backups[0]
            print(f"âš ï¸  Ã‰tat principal introuvable, utilisation du backup: {state_path.name}")
        else:
            print("âŒ Aucun Ã©tat d'entraÃ®nement trouvÃ©")
            print("ğŸ’¡ L'entraÃ®nement dÃ©marrera depuis le dÃ©but")
            print("="*70 + "\n")
            return
    
    # Charger l'Ã©tat
    try:
        state = torch.load(state_path, map_location='cpu')
    except:
        state = torch.load(state_path, map_location='cpu', weights_only=False)
    
    # Afficher les infos
    print(f"\nâœ… Ã‰tat d'entraÃ®nement trouvÃ©: {state_path.name}")
    print(f"\nğŸ“… DerniÃ¨re sauvegarde: {state.get('timestamp', 'inconnu')}")
    print(f"\nğŸ”¢ Progression:")
    print(f"   â€¢ Ã‰poque: {state.get('epoch', 0)}")
    print(f"   â€¢ Batch actuel: {state.get('batch_idx', 0)}")
    print(f"   â€¢ Total batches traitÃ©s: {state.get('total_batches_processed', 0):,}")
    print(f"\nğŸ“Š MÃ©triques:")
    print(f"   â€¢ Train Loss: {state.get('train_loss', 0):.4f}")
    print(f"   â€¢ Val Loss: {state.get('val_loss', 0):.4f}")
    print(f"   â€¢ Best Val Loss: {state.get('best_val_loss', float('inf')):.4f}")
    
    # Estimation de la progression
    total_batches = state.get('total_batches_processed', 0)
    if total_batches > 0:
        print(f"\nğŸ“ˆ Estimation:")
        # En moyenne 10-20k batches par dataset de 30k exemples
        estimated_examples = total_batches * 8  # batch_size = 8
        print(f"   â€¢ Exemples dÃ©jÃ  vus: ~{estimated_examples:,}")
        print(f"   â€¢ Prochaine sauvegarde dans: {1000 - (state.get('batch_idx', 0) % 1000)} batches")
    
    print(f"\nğŸ’¡ Commande pour reprendre:")
    print(f"   python LoRAFineTuning.py")
    print(f"   â†’ L'entraÃ®nement reprendra automatiquement au batch {state.get('batch_idx', 0) + 1}")
    
    print("="*70 + "\n")

if __name__ == "__main__":
    check_training_state()
